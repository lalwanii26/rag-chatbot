## rag-chatbot

Here's a guide to building a chatbot that responds to queries based on the content of your documents, rather than the information it has learned in training using Retrieval Augmented Generation (RAG), a common LLM application that retrieves contextual documents from an external dataset.

1. Document Loading: the fundamentals of data loading and discover over 80 unique loaders LangChain provides to access diverse data sources, including audio and video. 
2. Document Splitting: the best practices and considerations for splitting data. 
3. Vector stores and embeddings: the concept of embeddings and explore vector store integrations within LangChain.
4. Retrieval: advanced techniques for accessing and indexing data in the vector store, enabling you to retrieve the most relevant information beyond semantic queries. 
5. Question Answering: a one-pass question-answering solution. 
6. Chat: how to track and select pertinent information from conversations and data sources using your own chatbot that allow you to interact with data using LangChain and LLMs.
